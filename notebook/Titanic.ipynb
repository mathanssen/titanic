{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "public-analysis",
   "metadata": {},
   "source": [
    "<span style=\"font-family: Segoe UI; font-size: 2.5em; font-weight: 300;\">THE TITANIC PROJECT</span>\n",
    "\n",
    "![](https://static1.squarespace.com/static/5006453fe4b09ef2252ba068/5095eabce4b06cb305058603/5095eabce4b02d37bef4c24c/1352002236895/100_anniversary_titanic_sinking_by_esai8mellows-d4xbme8.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silent-platinum",
   "metadata": {},
   "source": [
    "<span style=\"font-family: Segoe UI; font-size: 2EM; font-weight: 300;\">Summary</span>\n",
    "* [1. Introduction](#introduction)\n",
    "* [2. Environment Preparation](#envprep)\n",
    "    - [2.1 Library Imports](#libimport)\n",
    "        - [2.2.1 Data Cleaning](#datacleaning)\n",
    "        - [2.2.2 Data Visualization](#datavisualization)\n",
    "        - [2.2.3 Data Engineering](#)\n",
    "        - [2.2.4 Data Modelling](#)\n",
    "        - [2.2.5 Settings](#)\n",
    "    - [2.2 Utils](#)\n",
    "    - [2.3 Data Imports](#)\n",
    "* [3. A bit of Exploratory Data Analysis](#)\n",
    "    - [3.1 Age](#)\n",
    "    - [3.2 Fare](#)\n",
    "    - [3.3 Pclass](#)\n",
    "    - [3.4 Sex](#)\n",
    "    - [3.5 SibSp](#)\n",
    "    - [3.6 Parch](#)\n",
    "    - [3.7 Embarked](#)\n",
    "* [4. Feature Engineering & Data Cleaning](#)\n",
    "    - [4.1 Merge Train & Test for Transformation](#)\n",
    "    - [4.2 Encoding Sex](#)\n",
    "    - [4.3 Title](#)\n",
    "    - [4.4 Name Length](#)\n",
    "    - [4.5 One-hot Encode Embarked & Label Encode Title](#)\n",
    "    - [4.6 Family Size](#)\n",
    "    - [4.7 Label Encoding Family Size](#)\n",
    "    - [4.8 FamilyName](#)\n",
    "    - [4.9 Cabin](#)\n",
    "    - [4.10 Cleaning Ticket](#)\n",
    "    - [4.11 Ticket Frequency](#)\n",
    "    - [4.12 One-hot Encoding Ticket](#)\n",
    "    - [4.13 Fare into Categorical Bins](#)\n",
    "    - [4.14 Additional Derived Features from Feature Relationships](#)\n",
    "    - [4.15 Remove Constant Columns](#)\n",
    "* [5. Imputation of Missing Values](#)\n",
    "* [6. Final Adjustments](#)\n",
    "    - [6.1 Create Age Banc](#)\n",
    "    - [6.2 Obtain Features for Children & Seniors](#)\n",
    "    - [6.3 Standard Scaling Data](#)\n",
    "    - [6.4 Split Data Back to Train & Test](#)\n",
    "* [7. Checking feature Importance & Correlations](#)\n",
    "* [8. Preparation of Train & Test Data](#)\n",
    "    - [8.1 Split the Data](#)\n",
    "    - [8.2 Cross Validation (K-Fold)](#)\n",
    "* [9. Model Development](#)\n",
    "    - [9.1 Model Evaluation](#)\n",
    "    - [9.2 Prediction](#)\n",
    "        - [9.2.1 AdaBoost](#)\n",
    "        - [9.2.2 Bagging](#)\n",
    "        - [9.2.3 Gradient Boosting](#)\n",
    "        - [9.2.4 Extra Trees](#)\n",
    "        - [9.2.5 Random Forest](#)\n",
    "        - [9.2.6 Gaussian Process](#)\n",
    "        - [9.2.7 Logistic Regression](#)\n",
    "        - [9.2.8 Ridge](#)\n",
    "        - [9.2.9 Perceptron](#)\n",
    "        - [9.2.10 Passive Agressive](#)\n",
    "        - [9.2.11 SGD](#)\n",
    "        - [9.2.12 Gaussian Naive Bayes](#)\n",
    "        - [9.2.13 Bernoulli](#)\n",
    "        - [9.2.14 K-Nearest Neighbors](#)\n",
    "        - [9.2.15 Support Vector Clustering](#)\n",
    "        - [9.2.16 Linear SVC](#)\n",
    "        - [9.2.17 NuSVC](#)\n",
    "        - [9.2.18 Decision Tree](#)\n",
    "        - [9.2.19 Linear Discriminant Analysis](#)\n",
    "        - [9.2.20 XGBoost](#)\n",
    "        - [9.2.21 Keras](#)\n",
    "    - [9.3 Model Performance](#)\n",
    "    - [9.4 Stack](#)\n",
    "    - [9.5 Voting](#)\n",
    "    - [9.6 Tunning Parameters](#)\n",
    "* [10. Submission](#)\n",
    "    - [10.1. Using Stack](#)\n",
    "    - [10.2. Using Keras](#)\n",
    "    - [10.3. Using Voting](#)\n",
    "    - [10.4. Final Adjustments](#)\n",
    "* [11. Credits](#)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binding-chamber",
   "metadata": {},
   "source": [
    "<a id=\"introduction\"></a>\n",
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confirmed-subscription",
   "metadata": {},
   "source": [
    "#### Goal\n",
    "* The competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\n",
    "\n",
    "#### Details & Description of Features:\n",
    "\n",
    "* PassengerID\n",
    "* Survived - (0 = No, 1 = Yes)\n",
    "* Pclass - Passenger Class (1 = 1st, 2 = 2nd, 3 = 3rd)\n",
    "* Name\n",
    "* Sex\n",
    "* Age\n",
    "* SibSp - Number of Siblings/Spouses Aboard\n",
    "* Parch - Number of Parents/Children Aboard\n",
    "* Ticket - Ticket Number\n",
    "* Fare - Passenger Fare in British pound\n",
    "* Cabin - Cabin Number\n",
    "* Embarked - Port of Embarkation (C = Cherbourg, Q = Queenstown, S = Southampton)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "settled-traffic",
   "metadata": {},
   "source": [
    "<a id=\"envprep\"></a>\n",
    "# 2. Environment Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dressed-index",
   "metadata": {},
   "source": [
    "<a id=\"libimport\"></a>\n",
    "### 2.1 Library Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "general-reflection",
   "metadata": {},
   "source": [
    "<a id=\"datacleaning\"></a>\n",
    "#### 2.1.1 Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-segment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dutch-airline",
   "metadata": {},
   "source": [
    "<a id=\"datavisualization\"></a>\n",
    "#### 2.1.2. Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "packed-visiting",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(rc={\"font.size\":18,\"axes.titlesize\":30,\"axes.labelsize\":18,\n",
    "            \"axes.titlepad\":22, \"axes.labelpad\":18, \"legend.fontsize\":15,\n",
    "            \"legend.title_fontsize\":15, \"figure.titlesize\":35})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apart-prisoner",
   "metadata": {},
   "source": [
    "#### 2.1.3. Data Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amber-march",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optbinning import OptimalBinning\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interpreted-institution",
   "metadata": {},
   "source": [
    "#### 2.1.4. Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wired-needle",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import *\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attempted-lunch",
   "metadata": {},
   "source": [
    "#### 2.1.5. Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lasting-percentage",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollywood-medication",
   "metadata": {},
   "source": [
    "### 2.2. Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "different-legislature",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_missing(df):    \n",
    "    missing = df.isnull().sum()\n",
    "    missing_percentage = df.isnull().sum() / df.isnull().count() * 100\n",
    "    missing_percentage = round(missing_percentage, 1)\n",
    "    missing_data = pd.concat([missing, missing_percentage], axis=1, keys=['Total', '%'])\n",
    "    missing_data = missing_data[missing_data['Total'] > 0].sort_values(by=['%'], ascending=False)\n",
    "    \n",
    "    return missing_data\n",
    "\n",
    "def calc_vif(X):\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"variables\"] = X.columns\n",
    "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "    return(vif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selected-helen",
   "metadata": {},
   "source": [
    "### 2.3. Data Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unusual-making",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../data/train.csv\")\n",
    "df_test = pd.read_csv(\"../data/test.csv\")\n",
    "df_submission = pd.read_csv(\"../data/gender_submission.csv\")\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thirty-tsunami",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welsh-tactics",
   "metadata": {},
   "source": [
    "# 3. A bit of Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premier-edgar",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organic-contractor",
   "metadata": {},
   "source": [
    "### 3.1 Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaging-acoustic",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(22,8))\n",
    "kde = sns.kdeplot(x=\"Age\", data=df_train, cut=0, hue=\"Survived\", fill=True, legend=True, palette=\"plasma_r\")\n",
    "\n",
    "plt.xlim(0)\n",
    "\n",
    "kde.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "kde.xaxis.set_major_formatter(ticker.ScalarFormatter())\n",
    "\n",
    "fig.suptitle(\"AGE BY SURVIVED\", x=0.125, y=1.0, ha='left', fontweight=100, fontfamily='Segoe UI', size=39);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuing-assessment",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(22, 8))\n",
    "hist = sns.histplot(df_train[\"Age\"], color=\"springgreen\", kde=True, bins=50, label=\"Train\")\n",
    "hist = sns.histplot(df_test[\"Age\"], color=\"gold\", kde=True, bins=50, label=\"Test\")\n",
    "\n",
    "plt.xlim(0)\n",
    "\n",
    "title = fig.suptitle(\"DISTRIBUITION OF AGE IN TRAIN & TEST\", x=0.125, y=1.01, ha='left', \n",
    "                     fontweight=100, fontfamily='Segoe UI', size=39)\n",
    "\n",
    "hist.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "hist.xaxis.set_major_formatter(ticker.ScalarFormatter())\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spiritual-desperate",
   "metadata": {},
   "source": [
    "### 3.2. Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "novel-omaha",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(22,8))\n",
    "kde = sns.kdeplot(x=\"Fare\", data=df_train, cut=0, hue=\"Survived\", fill=True, legend=True, palette=\"mako_r\")\n",
    "\n",
    "kde.xaxis.set_major_locator(ticker.MultipleLocator(10))\n",
    "kde.xaxis.set_major_formatter(ticker.ScalarFormatter())\n",
    "\n",
    "plt.xlim(0)\n",
    "\n",
    "fig.suptitle(\"FARE BY SURVIVED\", x=0.125, y=1.01, ha='left',fontweight=100, fontfamily='Segoe UI', size=39);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuck-painting",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,8))\n",
    "kde = sns.kdeplot(x=\"Fare\", data=df_train, cut=0, clip=[0,180], hue=\"Survived\", fill=True, legend=True, palette=\"mako_r\")\n",
    "\n",
    "plt.xlim(0)\n",
    "\n",
    "kde.xaxis.set_major_locator(ticker.MultipleLocator(4))\n",
    "kde.xaxis.set_major_formatter(ticker.ScalarFormatter())\n",
    "\n",
    "fig.suptitle(\"FARE BY SURVIVED - CLIPPED TO REMOVE OUTLIERS\", x=0.12, y=1.01, ha='left', \n",
    "             fontweight=100, fontfamily='Segoe UI', size=37);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bright-wichita",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,8))\n",
    "\n",
    "dist = sns.histplot(df_train[(df_train.Fare > 0) & (df_train.Fare <=180)]['Fare'],\n",
    "                    color=\"gold\", \n",
    "                    kde=True, \n",
    "                    bins=50, \n",
    "                    label='Train')\n",
    "\n",
    "dist = sns.histplot(df_test[(df_test.Fare > 0) & (df_test.Fare <=180)]['Fare'],\n",
    "                    color=\"crimson\", \n",
    "                    kde=True, \n",
    "                    bins=50, \n",
    "                    label='Test')\n",
    "\n",
    "title = fig.suptitle(\"DISTRIBUTION OF FARE IN TRAIN & TEST\", \n",
    "                     x=0.12, \n",
    "                     y=1.01, \n",
    "                     ha='left',\n",
    "                     fontweight=100, \n",
    "                     fontfamily='Segoe UI', \n",
    "                     size=37)\n",
    "\n",
    "plt.xlim(0)\n",
    "\n",
    "dist.xaxis.set_major_locator(ticker.MultipleLocator(4))\n",
    "dist.xaxis.set_major_formatter(ticker.ScalarFormatter())\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legendary-teens",
   "metadata": {},
   "source": [
    "### 3.3. Pclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legal-standard",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = sns.catplot(x=\"Pclass\", \n",
    "                 hue=\"Survived\", \n",
    "                 kind=\"count\", \n",
    "                 data=df_train,\n",
    "                 aspect = 3.5, \n",
    "                 legend=True, \n",
    "                 palette=\"YlGnBu\")\n",
    "\n",
    "title = c1.fig.suptitle(\"COUNT BY PCLASS\", \n",
    "                        x=0.04, \n",
    "                        y=1.12, \n",
    "                        ha='left', \n",
    "                        fontweight=100, \n",
    "                        fontfamily='Segoe UI', \n",
    "                        size=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "international-stylus",
   "metadata": {},
   "source": [
    "### 3.4. Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instrumental-movement",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = sns.catplot(x=\"Sex\", \n",
    "                 hue=\"Survived\", \n",
    "                 kind=\"count\", \n",
    "                 data=df_train,\n",
    "                 aspect = 3.5, \n",
    "                 legend=True, \n",
    "                 palette=\"YlGnBu\")\n",
    "\n",
    "title = c1.fig.suptitle(\"COUNT BY SEX\", \n",
    "                        x=0.04, \n",
    "                        y=1.12, \n",
    "                        ha='left', \n",
    "                        fontweight=100, \n",
    "                        fontfamily='Segoe UI', \n",
    "                        size=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "violent-perception",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(x=\"Sex\", y=\"Survived\", data=df_train,kind=\"bar\", palette = \"YlGnBu\")\n",
    "g.set_ylabels(\"Survival probability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compliant-traveler",
   "metadata": {},
   "source": [
    "### 3.5. SibSp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incredible-strip",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = sns.catplot(x=\"SibSp\", \n",
    "                 hue=\"Survived\", \n",
    "                 kind=\"count\", \n",
    "                 data=df_train,\n",
    "                 aspect = 3.5, \n",
    "                 legend=True, \n",
    "                 palette=\"YlGnBu\")\n",
    "\n",
    "title = c1.fig.suptitle(\"COUNT BY SibSp\", \n",
    "                        x=0.04, \n",
    "                        y=1.12, \n",
    "                        ha='left', \n",
    "                        fontweight=100, \n",
    "                        fontfamily='Segoe UI', \n",
    "                        size=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "completed-watershed",
   "metadata": {},
   "source": [
    "### 3.6. Parch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-tracker",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = sns.catplot(x=\"Parch\", \n",
    "                 hue=\"Survived\", \n",
    "                 kind=\"count\", \n",
    "                 data=df_train,\n",
    "                 aspect = 3.5, \n",
    "                 legend=True, \n",
    "                 palette=\"YlGnBu\")\n",
    "\n",
    "title = c1.fig.suptitle(\"COUNT BY Parch\", \n",
    "                        x=0.04, \n",
    "                        y=1.12, \n",
    "                        ha='left', \n",
    "                        fontweight=100, \n",
    "                        fontfamily='Segoe UI', \n",
    "                        size=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monetary-disease",
   "metadata": {},
   "source": [
    "### 3.7. Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legislative-pointer",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = sns.catplot(x=\"Embarked\", \n",
    "                 hue=\"Survived\", \n",
    "                 kind=\"count\", \n",
    "                 data=df_train,\n",
    "                 aspect = 3.5, \n",
    "                 legend=True, \n",
    "                 palette=\"YlGnBu\")\n",
    "\n",
    "title = c1.fig.suptitle(\"COUNT BY Embarked\", \n",
    "                        x=0.04, \n",
    "                        y=1.12, \n",
    "                        ha='left', \n",
    "                        fontweight=100, \n",
    "                        fontfamily='Segoe UI', \n",
    "                        size=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpha-throat",
   "metadata": {},
   "source": [
    "# 4. Feature Engineering & Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inside-change",
   "metadata": {},
   "source": [
    "### 4.1. Merge Train & Test for Transformation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graduate-browser",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.concat([df_train, df_test]).reset_index(drop=True)\n",
    "\n",
    "df_train_test = df_train.sample(frac=0.2,random_state=123)\n",
    "y_train_test = df_train_test[[\"Survived\", \"PassengerId\"]]\n",
    "df_train_test = df_train_test.drop([\"Survived\"], axis=1)\n",
    "list_index = df_train_test.index.values.tolist()\n",
    "df_train_train = df_train[~df_train.index.isin(list_index)]\n",
    "full_df_model = pd.concat([df_train_test, df_train_train])\n",
    "\n",
    "train_shape = df_train.shape\n",
    "test_shape = df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "universal-convertible",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(full_df.shape, df_train.shape, df_train_train.shape, df_train_test.shape, full_df_model.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "danish-hacker",
   "metadata": {},
   "source": [
    "### 4.2. Encoding Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contemporary-award",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.loc[:, 'Sex'] = (full_df.loc[:, 'Sex'] == 'female').astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "configured-ocean",
   "metadata": {},
   "source": [
    "### 4.3. Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "casual-simon",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.Name.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decimal-remainder",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df[\"Title\"] = full_df[\"Name\"]\n",
    "full_df[\"Title\"] = full_df[\"Name\"].str.extract(\"([A-Za-z]+)\\.\", expand=True)\n",
    "\n",
    "c1 = sns.catplot(x=\"Title\", hue=\"Survived\", kind=\"count\", data=full_df[:train_shape[0]],\n",
    "                 aspect = 3.5, legend=True, palette=\"YlGnBu\")\n",
    "\n",
    "title = c1.fig.suptitle(\"COUNT BY TITLE\", x=0.04, y=1.12, ha='left',\n",
    "             fontweight=100, fontfamily='Segoe UI', size=42)\n",
    "\n",
    "# Replacing rare titles \n",
    "mapping = {'Mlle': 'Miss', 'Ms': 'Miss', 'Mme': 'Mrs', 'Major': 'Other', \n",
    "           'Col': 'Other', 'Dr' : 'Other', 'Rev' : 'Other', 'Capt': 'Other', \n",
    "           'Jonkheer': 'Royal', 'Sir': 'Royal', 'Lady': 'Royal', \n",
    "           'Don': 'Royal', 'Countess': 'Royal', 'Dona': 'Royal'}\n",
    "           \n",
    "full_df.replace({'Title': mapping}, inplace=True)\n",
    "\n",
    "c2 = sns.catplot(x=\"Title\", hue=\"Survived\", kind=\"count\", data=full_df[:train_shape[0]],\n",
    "                 aspect = 3.5, legend=True, palette=\"YlGnBu\")\n",
    "c2.fig.suptitle(\"COUNT BY TITLE AGGREGATED\", x=0.04, y=1.12, ha='left',\n",
    "             fontweight=100, fontfamily='Segoe UI', size=42);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radio-center",
   "metadata": {},
   "source": [
    "### 4.4. Name Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boring-gossip",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df[\"Name_Length\"] = full_df.Name.str.replace(\"[^a-zA-Z]\", \"\").str.len()\n",
    "\n",
    "fig, ax = plt.subplots(ncols=1, figsize=(20,8))\n",
    "kde = sns.kdeplot(x=\"Name_Length\", data=full_df[:train_shape[0]], cut=True,\n",
    "                  hue=\"Survived\", fill=True, ax=ax, palette=\"mako_r\")\n",
    "\n",
    "kde.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "kde.xaxis.set_major_formatter(ticker.ScalarFormatter())\n",
    "\n",
    "fig.suptitle(\"NAME_LENGTH BY SURVIVED\", x=0.125, y=1.01, ha='left',\n",
    "             fontweight=100, fontfamily='Lato', size=42);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "measured-burke",
   "metadata": {},
   "source": [
    "### 4.5. One-hot Encode Embarked & Label Encode Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consecutive-mouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['Title_C'] = full_df['Title']\n",
    "\n",
    "full_df['Embarked'] = full_df['Embarked'].fillna('S')\n",
    "full_df = pd.get_dummies(full_df, columns=[\"Embarked\",\"Title_C\"],prefix=[\"Emb\",\"Title\"], drop_first=False)\n",
    "\n",
    "title_dict = {'Mr': 1, 'Miss': 2, 'Mrs': 3, 'Other': 4, 'Royal': 5, 'Master': 6}\n",
    "full_df['Title'] = full_df['Title'].map(title_dict).astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "happy-opposition",
   "metadata": {},
   "source": [
    "### 4.6. Derive Family Size Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "third-andorra",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['Family_Size'] = full_df['Parch'] + full_df['SibSp'] + 1\n",
    "full_df['Fsize_Cat'] = full_df['Family_Size'].map(lambda val: 'Alone' if val <= 1 else ('Small' if val < 5 else 'Big'))\n",
    "full_df[\"isAlone\"] = full_df.Family_Size.apply(lambda x: 1 if x==1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worst-reynolds",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=1, figsize=(20,8))\n",
    "kde = sns.kdeplot(x=\"Family_Size\", data=full_df[:train_shape[0]], cut=True,\n",
    "                  hue=\"Survived\", fill=True, ax=ax, palette=\"mako_r\")\n",
    "\n",
    "kde.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "kde.xaxis.set_major_formatter(ticker.ScalarFormatter())\n",
    "\n",
    "plt.xlim(1)\n",
    "\n",
    "fig.suptitle(\"FAMILY SIZE BY SURVIVED\", x=0.125, y=1.01, ha='left',\n",
    "             fontweight=100, fontfamily='Segoe UI', size=42);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optimum-nickel",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = sns.catplot(x=\"Fsize_Cat\", \n",
    "                 hue=\"Survived\", \n",
    "                 kind=\"count\", \n",
    "                 data=full_df[:train_shape[0]],\n",
    "                 aspect = 3.5, \n",
    "                 legend=True, \n",
    "                 palette=\"YlGnBu\")\n",
    "\n",
    "title = c1.fig.suptitle(\"COUNT BY Fsize_Cat\", \n",
    "                        x=0.04, \n",
    "                        y=1.12, \n",
    "                        ha='left', \n",
    "                        fontweight=100, \n",
    "                        fontfamily='Segoe UI', \n",
    "                        size=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposed-donor",
   "metadata": {},
   "source": [
    "### 4.7. Label Encoding Family Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjustable-stylus",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fsize_dict = {'Alone':3, 'Small':2, 'Big':1}\n",
    "full_df['Fsize_Cat'] = full_df['Fsize_Cat'].map(Fsize_dict).astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "differential-edward",
   "metadata": {},
   "source": [
    "### 4.8. Extract FamilyName Feature from Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cognitive-photography",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['Family_Name'] = full_df['Name'].str.extract('([A-Za-z]+.[A-Za-z]+)\\,', expand=True)\n",
    "full_df_model['Family_Name'] = full_df_model['Name'].str.extract('([A-Za-z]+.[A-Za-z]+)\\,', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "logical-trustee",
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAN_SURVIVAL_RATE = round(np.mean(df_train['Survived']), 4)\n",
    "\n",
    "full_df['Family_Friends_Surv_Rate'] = MEAN_SURVIVAL_RATE\n",
    "full_df['Surv_Rate_Invalid'] = 1\n",
    "\n",
    "for _, grp_df in full_df[['Survived', 'Family_Name', 'Fare', 'Ticket', 'PassengerId']].groupby(['Family_Name', 'Fare']):                       \n",
    "    if (len(grp_df) > 1):\n",
    "        if(grp_df['Survived'].isnull().sum() != len(grp_df)):\n",
    "            for ind, row in grp_df.iterrows():\n",
    "                full_df.loc[full_df['PassengerId'] == row['PassengerId'],\n",
    "                            'Family_Friends_Surv_Rate'] = round(grp_df['Survived'].mean(), 4)\n",
    "                full_df.loc[full_df['PassengerId'] == row['PassengerId'],\n",
    "                            'Surv_Rate_Invalid'] = 0\n",
    "\n",
    "for _, grp_df in full_df[['Survived', 'Family_Name', 'Fare', 'Ticket', 'PassengerId', \n",
    "                          'Family_Friends_Surv_Rate']].groupby('Ticket'):\n",
    "    if (len(grp_df) > 1):\n",
    "        for ind, row in grp_df.iterrows():\n",
    "            if (row['Family_Friends_Surv_Rate'] == 0.) | (row['Family_Friends_Surv_Rate'] == MEAN_SURVIVAL_RATE):\n",
    "                if(grp_df['Survived'].isnull().sum() != len(grp_df)):\n",
    "                    full_df.loc[full_df['PassengerId'] == row['PassengerId'],\n",
    "                                'Family_Friends_Surv_Rate'] = round(grp_df['Survived'].mean(), 4)\n",
    "                    full_df.loc[full_df['PassengerId'] == row['PassengerId'],\n",
    "                                'Surv_Rate_Invalid'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-statistics",
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAN_SURVIVAL_RATE = round(np.mean(df_train_train['Survived']), 4)\n",
    "\n",
    "full_df_model['Family_Friends_Surv_Rate'] = MEAN_SURVIVAL_RATE\n",
    "full_df_model['Surv_Rate_Invalid'] = 1\n",
    "\n",
    "for _, grp_df in full_df_model[['Survived', 'Family_Name', 'Fare', 'Ticket', 'PassengerId']].groupby(['Family_Name', 'Fare']):                       \n",
    "    if (len(grp_df) > 1):\n",
    "        if(grp_df['Survived'].isnull().sum() != len(grp_df)):\n",
    "            for ind, row in grp_df.iterrows():\n",
    "                full_df_model.loc[full_df_model['PassengerId'] == row['PassengerId'],\n",
    "                            'Family_Friends_Surv_Rate'] = round(grp_df['Survived'].mean(), 4)\n",
    "                full_df_model.loc[full_df_model['PassengerId'] == row['PassengerId'],\n",
    "                            'Surv_Rate_Invalid'] = 0\n",
    "\n",
    "for _, grp_df in full_df_model[['Survived', 'Family_Name', 'Fare', 'Ticket', 'PassengerId', \n",
    "                          'Family_Friends_Surv_Rate']].groupby('Ticket'):\n",
    "    if (len(grp_df) > 1):\n",
    "        for ind, row in grp_df.iterrows():\n",
    "            if (row['Family_Friends_Surv_Rate'] == 0.) | (row['Family_Friends_Surv_Rate'] == MEAN_SURVIVAL_RATE):\n",
    "                if(grp_df['Survived'].isnull().sum() != len(grp_df)):\n",
    "                    full_df_model.loc[full_df_model['PassengerId'] == row['PassengerId'],\n",
    "                                'Family_Friends_Surv_Rate'] = round(grp_df['Survived'].mean(), 4)\n",
    "                    full_df_model.loc[full_df_model['PassengerId'] == row['PassengerId'],\n",
    "                                'Surv_Rate_Invalid'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "systematic-mixture",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = full_df.drop([\"Name\", \"Family_Name\"], axis=1)\n",
    "full_df_model = full_df_model.drop([\"Name\", \"Family_Name\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abstract-prayer",
   "metadata": {},
   "source": [
    "### 4.9. Cleaning & Encoding of the Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passive-ribbon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values with 'U' for Cabin\n",
    "full_df['Cabin_Clean'] = full_df['Cabin'].fillna('U')\n",
    "full_df['Cabin_Clean'] = full_df['Cabin_Clean'].str.strip(' ').str[0]\n",
    "# Label Encoding\n",
    "cabin_dict = {'A':9, 'B':8, 'C':7, 'D':6, 'E':5, 'F':4, 'G':3, 'T':2, 'U':1}\n",
    "full_df['Cabin_Clean'] = full_df['Cabin_Clean'].map(cabin_dict).astype('int')\n",
    "full_df.drop([\"Cabin\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "administrative-programmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=1, figsize=(23,8))\n",
    "sns.histplot(x=\"Cabin_Clean\", data=full_df[:train_shape[0]], hue=\"Survived\", fill=True, ax=ax, palette=\"nipy_spectral\", \n",
    "             kde=True)\n",
    "fig.suptitle(\"CABIN_CLEAN BY SURVIVED\", x=0.125, y=1.01, ha='left',\n",
    "             fontweight=100, fontfamily='Segoe UI', size=42);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "measured-objective",
   "metadata": {},
   "source": [
    "### 4.10. Cleaning the Ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-shame",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_ticket(each_ticket):\n",
    "    prefix = re.sub(r'[^a-zA-Z]', '', each_ticket)\n",
    "    if(prefix):\n",
    "        return prefix\n",
    "    else:\n",
    "        return \"NUM\"\n",
    "\n",
    "full_df[\"Tkt_Clean\"] = full_df.Ticket.apply(clean_ticket)\n",
    "\n",
    "fig, ax = plt.subplots(ncols=1, figsize=(23,8))\n",
    "sns.countplot(x=\"Tkt_Clean\", data=full_df[:train_shape[0]], hue=\"Survived\", fill=True, ax=ax, palette=\"bwr_r\")\n",
    "fig.suptitle(\"TKT_CLEAN BY SURVIVED\", x=0.125, y=1.01, ha='left',\n",
    "             fontweight=100, fontfamily='Segoe UI', size=42);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conservative-going",
   "metadata": {},
   "source": [
    "### 4.11. Derive the Ticket Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressive-electron",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ticket_group = df_train_train.groupby('Ticket')['Ticket'].count()\n",
    "# df_ticket = pd.DataFrame({'Ticket':ticket_group.index, 'Ticket_Frequency':ticket_group.values})\n",
    "# full_df = full_df.merge(df_ticket, on='Ticket', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-asbestos",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['Ticket_Frequency'] = full_df.groupby('Ticket')['Ticket'].transform('count')\n",
    "full_df.drop([\"Ticket\"], axis=1, inplace=True)\n",
    "fig, ax = plt.subplots(ncols=1, figsize=(23,8))\n",
    "sns.countplot(x=\"Ticket_Frequency\", data=full_df[:train_shape[0]], hue=\"Survived\", fill=True, ax=ax, palette=\"PiYG_r\")\n",
    "\n",
    "fig.suptitle(\"TICKET_FREQUENCY BY SURVIVED\", x=0.125, y=1.01, ha='left',\n",
    "             fontweight=100, fontfamily='Lato', size=42);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "similar-blackjack",
   "metadata": {},
   "source": [
    "### 4.12. One-hot Encoding Ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "systematic-omaha",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.get_dummies(full_df, columns=[\"Tkt_Clean\"], prefix=[\"Tkt\"], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "danish-vampire",
   "metadata": {},
   "source": [
    "### 4.13. Fare into Categorical Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-verse",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fare_cat(fare):\n",
    "    if fare <= 7.0:\n",
    "        return 1\n",
    "    elif fare <= 39 and fare > 7.0:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "full_df.loc[:, 'Fare_Cat'] = full_df['Fare'].apply(fare_cat).astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "differential-scotland",
   "metadata": {},
   "source": [
    "### 4.14. Additional Derived Features from Feature Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifteen-puppy",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.loc[:, 'Fare_Family_Size'] = full_df['Fare']/full_df['Family_Size']\n",
    "\n",
    "full_df.loc[:, 'Fare_Cat_Pclass'] = full_df['Fare_Cat']*full_df['Pclass']\n",
    "full_df.loc[:, 'Fare_Cat_Title'] = full_df['Fare_Cat']*full_df['Title']\n",
    "\n",
    "full_df.loc[:, 'Fsize_Cat_Title'] = full_df['Fsize_Cat']*full_df['Title']\n",
    "full_df.loc[:, 'Fsize_Cat_Fare_Cat'] = full_df['Fare_Cat']/full_df['Fsize_Cat'].astype('int')\n",
    "\n",
    "full_df.loc[:, 'Pclass_Title'] = full_df['Pclass']*full_df['Title']\n",
    "full_df.loc[:, 'Fsize_Cat_Pclass'] = full_df['Fsize_Cat']*full_df['Pclass']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naughty-mathematics",
   "metadata": {},
   "source": [
    "### 4.15. Remove Constant Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painful-expense",
   "metadata": {},
   "outputs": [],
   "source": [
    "colsToRemove = []\n",
    "cols = ['Tkt_AQ', 'Tkt_AS', 'Tkt_C', 'Tkt_CA',\n",
    "         'Tkt_CASOTON', 'Tkt_FC', 'Tkt_FCC', 'Tkt_Fa', 'Tkt_LINE', 'Tkt_LP',\n",
    "         'Tkt_NUM', 'Tkt_PC', 'Tkt_PP', 'Tkt_PPP', 'Tkt_SC', 'Tkt_SCA',\n",
    "         'Tkt_SCAH', 'Tkt_SCAHBasle', 'Tkt_SCOW', 'Tkt_SCPARIS', 'Tkt_SCParis',\n",
    "         'Tkt_SOC', 'Tkt_SOP', 'Tkt_SOPP', 'Tkt_SOTONO', 'Tkt_SOTONOQ',\n",
    "         'Tkt_SP', 'Tkt_STONO', 'Tkt_STONOQ', 'Tkt_SWPP', 'Tkt_WC', \n",
    "         'Tkt_WEP', 'Fare_Cat', 'Fare_Family_Size', 'Fare_Cat_Pclass',\n",
    "         'Fare_Cat_Title', 'Fsize_Cat_Title', 'Fsize_Cat_Fare_Cat', \n",
    "         'Pclass_Title', 'Fsize_Cat_Pclass']\n",
    "\n",
    "for col in cols:\n",
    "    if full_df[col][:train_shape[0]].std() == 0: \n",
    "        colsToRemove.append(col)\n",
    "\n",
    "# remove constant columns in the training set\n",
    "full_df.drop(colsToRemove, axis=1, inplace=True)\n",
    "print(\"Removed `{}` Constant Columns\\n\".format(len(colsToRemove)))\n",
    "print(colsToRemove)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "victorian-potato",
   "metadata": {},
   "source": [
    "# 5. Imputation of Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-pride",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"Survived\",'Family_Friends_Surv_Rate','Surv_Rate_Invalid']\n",
    "df = full_df.copy()\n",
    "df.loc[df.PassengerId.isin(full_df_model.PassengerId), features] = full_df_model[features]\n",
    "passenger_list = full_df_model[\"PassengerId\"].tolist()\n",
    "full_df_model = df[df[\"PassengerId\"].isin(passenger_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civilian-circle",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_features = ['Pclass', \n",
    "                'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Title',\n",
    "                 'Name_Length',\n",
    "                'Emb_C', 'Emb_Q', 'Emb_S','Family_Size',\n",
    "                 'Fsize_Cat', 'Family_Friends_Surv_Rate', 'Surv_Rate_Invalid',\n",
    "                 'Cabin_Clean','Ticket_Frequency', 'Tkt_AS', 'Tkt_C', 'Tkt_CA',\n",
    "                 'Tkt_CASOTON', 'Tkt_FC', 'Tkt_FCC', 'Tkt_Fa', 'Tkt_LINE',\n",
    "                 'Tkt_NUM', 'Tkt_PC', 'Tkt_PP', 'Tkt_PPP', 'Tkt_SC', 'Tkt_SCA',\n",
    "                 'Tkt_SCAH', 'Tkt_SCAHBasle', 'Tkt_SCOW', 'Tkt_SCPARIS', 'Tkt_SCParis',\n",
    "                 'Tkt_SOC', 'Tkt_SOP', 'Tkt_SOPP', 'Tkt_SOTONO', 'Tkt_SOTONOQ',\n",
    "                 'Tkt_SP', 'Tkt_STONO', 'Tkt_SWPP', 'Tkt_WC', \n",
    "                 'Tkt_WEP', 'Fare_Cat', 'Fare_Family_Size', 'Fare_Cat_Pclass',\n",
    "                 'Fare_Cat_Title', 'Fsize_Cat_Title', 'Fsize_Cat_Fare_Cat', \n",
    "                 'Pclass_Title', 'Fsize_Cat_Pclass']\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=10, missing_values=np.nan)\n",
    "imputer.fit(full_df[imp_features])\n",
    "full_df.loc[:, imp_features] = pd.DataFrame(imputer.transform(full_df[imp_features]), \n",
    "                                            index=full_df.index, columns = imp_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tender-civilization",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = KNNImputer(n_neighbors=10, missing_values=np.nan)\n",
    "imputer.fit(full_df_model[imp_features])\n",
    "full_df_model.loc[:, imp_features] = pd.DataFrame(imputer.transform(full_df_model[imp_features]), \n",
    "                                            index=full_df_model.index, columns = imp_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stretch-kitty",
   "metadata": {},
   "source": [
    "# 6. Final Adjustments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "martial-ownership",
   "metadata": {},
   "source": [
    "### 6.1. Create Age Band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinated-lyric",
   "metadata": {},
   "outputs": [],
   "source": [
    "optb = OptimalBinning(name=\"Age\", dtype=\"numerical\", solver=\"cp\")\n",
    "x = full_df[:train_shape[0]][\"Age\"].values\n",
    "y_train = full_df[:train_shape[0]][\"Survived\"]\n",
    "y = y_train[y_train.index.isin(df_train.index)]\n",
    "optb.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sufficient-press",
   "metadata": {},
   "outputs": [],
   "source": [
    "binning_table = optb.binning_table\n",
    "binning_table.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesser-appreciation",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_index = full_df.index.values.tolist()\n",
    "col = full_df[\"Age\"].values\n",
    "x_transform = optb.transform(col, metric=\"event_rate\")\n",
    "x_transform = pd.Series(x_transform, index=list_index)\n",
    "x_transform.value_counts()\n",
    "x_transform = x_transform.rename(\"Age_Band\")\n",
    "full_df = pd.concat((full_df, x_transform), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "married-earth",
   "metadata": {},
   "outputs": [],
   "source": [
    "optb = OptimalBinning(name=\"Age\", dtype=\"numerical\", solver=\"cp\")\n",
    "x = df_train_train[\"Age\"].values\n",
    "y_train = df_train_train[\"Survived\"]\n",
    "y = y_train[y_train.index.isin(df_train.index)]\n",
    "optb.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sonic-occasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "binning_table = optb.binning_table\n",
    "binning_table.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simple-annual",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_index = full_df_model.index.values.tolist()\n",
    "col = full_df_model[\"Age\"].values\n",
    "x_transform = optb.transform(col, metric=\"event_rate\")\n",
    "x_transform = pd.Series(x_transform, index=list_index)\n",
    "x_transform.value_counts()\n",
    "x_transform = x_transform.rename(\"Age_Band\")\n",
    "full_df_model = pd.concat((full_df_model, x_transform), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "still-system",
   "metadata": {},
   "source": [
    "### 6.2. Obtain Features for Children & Seniors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "massive-prediction",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['Child'] = full_df['Age'].map(lambda val:1 if val<18 else 0)\n",
    "full_df['Senior'] = full_df['Age'].map(lambda val:1 if val>70 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spare-angle",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, figsize=(23,8))\n",
    "\n",
    "sns.countplot(x=\"Child\", data=full_df[:train_shape[0]], hue=\"Survived\", fill=True, ax=ax[0], palette=\"PiYG_r\")\n",
    "sns.countplot(x=\"Senior\", data=full_df[:train_shape[0]], hue=\"Survived\", fill=True, ax=ax[1], palette=\"PiYG_r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "positive-trust",
   "metadata": {},
   "source": [
    "### 6.3. Standard Scaling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valued-harvey",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler_cols = ['Age', 'Fare', 'Name_Length', 'Family_Size',\n",
    "               'Ticket_Frequency', 'Fare_Family_Size', 'Fare_Cat_Pclass']\n",
    "std = StandardScaler()\n",
    "std.fit(full_df[scaler_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "announced-representation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_std = pd.DataFrame(std.transform(full_df[scaler_cols]), index=full_df.index, columns = scaler_cols)\n",
    "full_df.drop(scaler_cols, axis=1, inplace=True)\n",
    "full_df = pd.concat((full_df, df_std), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "julian-porter",
   "metadata": {},
   "source": [
    "### 6.4. Split Data back to Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enhanced-sunglasses",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"Survived\",'Family_Friends_Surv_Rate','Surv_Rate_Invalid', \"Age_Band\"]\n",
    "df = full_df.copy()\n",
    "df.loc[df.PassengerId.isin(full_df_model.PassengerId), features] = full_df_model[features]\n",
    "passenger_list = full_df_model[\"PassengerId\"].tolist()\n",
    "full_df_model = df[df[\"PassengerId\"].isin(passenger_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "present-essex",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_final = full_df[:train_shape[0]]\n",
    "df_test_final = full_df[train_shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-funeral",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_final.drop([\"Survived\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "internal-palestinian",
   "metadata": {},
   "source": [
    "# 7. Checking Feature Importance by Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-artwork",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_final.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-intersection",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mat = df_train_final.astype(float).corr()\n",
    "corr_mat_fil = corr_mat.loc[:, 'Survived'].sort_values(ascending=False)\n",
    "corr_mat_fil = pd.DataFrame(data=corr_mat_fil[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-ballet",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,14))\n",
    "bar = sns.barplot(x=corr_mat_fil.Survived, y=corr_mat_fil.index, data=corr_mat_fil, palette=\"Spectral\")\n",
    "title = bar.set_title(\"FEATURE CORRELATION\", x=0.0, y=1.01, ha='left',\n",
    "             fontweight=100, fontfamily='Segoe UI', size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scheduled-cream",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_corr = df_train_final.drop([\"PassengerId\"], axis=1)\n",
    "corrmat = df_corr.corr()\n",
    "sorted_corrs = corrmat['Survived'].abs().sort_values(ascending=False)\n",
    "print(sorted_corrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focal-diagram",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr = df_train_final.corr()\n",
    "top_corr_cols = corr[abs((corr.Survived)>=.0)].Survived.sort_values(ascending=False).keys()\n",
    "top_corr = corr.loc[top_corr_cols, top_corr_cols]\n",
    "dropSelf = np.zeros_like(top_corr)\n",
    "dropSelf[np.triu_indices_from(dropSelf)] = True\n",
    "plt.figure(figsize=(13, 13))\n",
    "sns.heatmap(top_corr, cmap=sns.diverging_palette(220, 10, as_cmap=True), annot=False, fmt=\".2f\", mask=dropSelf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "celtic-experiment",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = df_train_final.drop([\"Survived\", \"PassengerId\"], axis=1)\n",
    "X = X.assign(const=1)\n",
    "calc_vif(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minute-denver",
   "metadata": {},
   "source": [
    "# 8. Preparation of Train & Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlikely-premium",
   "metadata": {},
   "source": [
    "### 8.1. Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identified-warner",
   "metadata": {},
   "outputs": [],
   "source": [
    "passenger_train = df_train_train[\"PassengerId\"].tolist()\n",
    "df_train = full_df_model[full_df_model[\"PassengerId\"].isin(passenger_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baking-stopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "passenger_test = df_train_test[\"PassengerId\"].tolist()\n",
    "df_test = full_df_model[full_df_model[\"PassengerId\"].isin(passenger_test)]\n",
    "df_test.loc[df_test.PassengerId.isin(y_train_test.PassengerId), \"Survived\"] = y_train_test[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resident-incident",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop([\"Survived\", \"PassengerId\"], axis=1)\n",
    "y_train = df_train[\"Survived\"]\n",
    "X_test = df_test.drop([\"Survived\", \"PassengerId\"], axis=1)\n",
    "y_test = df_test[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separated-snake",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-return",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_passenger = passenger_train + passenger_test\n",
    "df_train_final = full_df[full_df[\"PassengerId\"].isin(all_passenger)]\n",
    "df_test_final = full_df[~full_df[\"PassengerId\"].isin(all_passenger)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iraqi-handy",
   "metadata": {},
   "source": [
    "### 8.2. Cross Validation (K-Fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sonic-shelter",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appointed-reproduction",
   "metadata": {},
   "source": [
    "# 9. Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaptive-iceland",
   "metadata": {},
   "source": [
    "### 9.1. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instructional-enemy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kfold_accuracy(model):\n",
    "    score = cross_val_score(model, X_train, y_train, cv=k_fold, scoring=\"accuracy\")\n",
    "    print(\"KFold Score:\", round(np.mean(score) * 100, 2))\n",
    "    \n",
    "    return score\n",
    "\n",
    "def get_accuracy(prediction):\n",
    "    score = round(accuracy_score(prediction, y_test)*100,2)\n",
    "    print(\"Accuracy\", score)\n",
    "    \n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welcome-litigation",
   "metadata": {},
   "source": [
    "### 9.2. Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "editorial-replication",
   "metadata": {},
   "source": [
    "#### 9.2.1. AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innocent-legend",
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_boost = AdaBoostClassifier()\n",
    "ada_boost.fit(X_train, y_train)\n",
    "prediction = ada_boost.predict(X_test)\n",
    "ada_boost_score = get_accuracy(prediction)\n",
    "ada_boost_kfold_score = get_kfold_accuracy(ada_boost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposite-tackle",
   "metadata": {},
   "source": [
    "#### 9.2.2. Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "together-needle",
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging = ensemble.BaggingClassifier()\n",
    "bagging.fit(X_train, y_train)\n",
    "prediction = bagging.predict(X_test)\n",
    "bagging_score = get_accuracy(prediction)\n",
    "bagging_kfold_score = get_kfold_accuracy(bagging)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "induced-richmond",
   "metadata": {},
   "source": [
    "#### 9.2.3. Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrapped-tooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_boosting = ensemble.GradientBoostingClassifier()\n",
    "gradient_boosting.fit(X_train, y_train)\n",
    "prediction = gradient_boosting.predict(X_test)\n",
    "gradient_boosting_score = get_accuracy(prediction)\n",
    "gradient_boosting_kfold_score = get_kfold_accuracy(gradient_boosting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "according-mineral",
   "metadata": {},
   "source": [
    "#### 9.2.4. Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceramic-campus",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_trees = ensemble.ExtraTreesClassifier()\n",
    "extra_trees.fit(X_train, y_train)\n",
    "prediction = extra_trees.predict(X_test)\n",
    "extra_trees_score = get_accuracy(prediction)\n",
    "extra_trees_kfold_score = get_kfold_accuracy(extra_trees)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "homeless-vaccine",
   "metadata": {},
   "source": [
    "#### 9.2.5. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "connected-circumstances",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = ensemble.RandomForestClassifier()\n",
    "random_forest.fit(X_train, y_train)\n",
    "prediction = random_forest.predict(X_test)\n",
    "random_forest_score = get_accuracy(prediction)\n",
    "random_forest_kfold_score = get_kfold_accuracy(random_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dirty-trace",
   "metadata": {},
   "source": [
    "#### 9.2.6. Gaussian Process Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mighty-seven",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_process = GaussianProcessClassifier()\n",
    "gaussian_process.fit(X_train, y_train)\n",
    "prediction = gaussian_process.predict(X_test)\n",
    "gaussian_process_score = get_accuracy(prediction)\n",
    "gaussian_process_kfold_score = get_kfold_accuracy(gaussian_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excited-active",
   "metadata": {},
   "source": [
    "#### 9.2.7. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attractive-petite",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_cv = linear_model.LogisticRegressionCV(max_iter=100000)\n",
    "logistic_regression_cv.fit(X_train, y_train)\n",
    "prediction = logistic_regression_cv.predict(X_test)\n",
    "logistic_regression_cv_score = get_accuracy(prediction)\n",
    "logistic_regression_cv_kfold_score = get_kfold_accuracy(logistic_regression_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dated-national",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression = LogisticRegression(random_state=1, max_iter=10000)\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "prediction = logistic_regression.predict(X_test)\n",
    "logistic_regression_score = get_accuracy(prediction)\n",
    "logistic_regression_kfold_score = get_kfold_accuracy(logistic_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-lebanon",
   "metadata": {},
   "source": [
    "#### 9.2.8. Ridge Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "architectural-burning",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = linear_model.RidgeClassifierCV()\n",
    "ridge.fit(X_train, y_train)\n",
    "prediction = ridge.predict(X_test)\n",
    "ridge_score = get_accuracy(prediction)\n",
    "ridge_kfold_score = get_kfold_accuracy(ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capital-volunteer",
   "metadata": {},
   "source": [
    "#### 9.2.9. Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-click",
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron = linear_model.Perceptron()\n",
    "perceptron.fit(X_train, y_train)\n",
    "prediction = perceptron.predict(X_test)\n",
    "perceptron_score = get_accuracy(prediction)\n",
    "perceptron_kfold_score = get_kfold_accuracy(perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hydraulic-shanghai",
   "metadata": {},
   "source": [
    "#### 9.2.10. Passive Aggressive Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "completed-spice",
   "metadata": {},
   "outputs": [],
   "source": [
    "passive_aggressive = linear_model.PassiveAggressiveClassifier()\n",
    "passive_aggressive.fit(X_train, y_train)\n",
    "prediction = passive_aggressive.predict(X_test)\n",
    "passive_aggressive_score = get_accuracy(prediction)\n",
    "passive_aggressive_kfold_score = get_kfold_accuracy(passive_aggressive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "roman-bleeding",
   "metadata": {},
   "source": [
    "#### 9.2.11. SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regular-panama",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdg = linear_model.SGDClassifier()\n",
    "sdg.fit(X_train, y_train)\n",
    "prediction = sdg.predict(X_test)\n",
    "sdg_score = get_accuracy(prediction)\n",
    "sdg_kfold_score = get_kfold_accuracy(sdg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "future-triple",
   "metadata": {},
   "source": [
    "#### 9.2.12. Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cathedral-orange",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_nb = naive_bayes.GaussianNB()\n",
    "gaussian_nb.fit(X_train, y_train)\n",
    "prediction = gaussian_nb.predict(X_test)\n",
    "gaussian_nb_score = get_accuracy(prediction)\n",
    "gaussian_nb_kfold_score = get_kfold_accuracy(gaussian_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analyzed-ethnic",
   "metadata": {},
   "source": [
    "#### 9.2.13. Bernoulli NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solved-switch",
   "metadata": {},
   "outputs": [],
   "source": [
    "bernoulli_nb = naive_bayes.BernoulliNB()\n",
    "bernoulli_nb.fit(X_train, y_train)\n",
    "prediction = bernoulli_nb.predict(X_test)\n",
    "bernoulli_nb_score = get_accuracy(prediction)\n",
    "bernoulli_nb_kfold_score = get_kfold_accuracy(bernoulli_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seven-institute",
   "metadata": {},
   "source": [
    "#### 9.2.14. kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "average-vision",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors = 13)\n",
    "knn.fit(X_train, y_train)\n",
    "prediction = knn.predict(X_test)\n",
    "knn_score = get_accuracy(prediction)\n",
    "knn_kfold_score = get_kfold_accuracy(knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cordless-cutting",
   "metadata": {},
   "source": [
    "#### 9.2.15. SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-alabama",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "svc = SVC(random_state=1, kernel='linear')\n",
    "svc.fit(X_train, y_train)\n",
    "prediction = svc.predict(X_test)\n",
    "svc_score = get_accuracy(prediction)\n",
    "svc_kfold_score = get_kfold_accuracy(svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "headed-experience",
   "metadata": {},
   "source": [
    "#### 9.2.16. Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "straight-sullivan",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_linear = LinearSVC(random_state=1, max_iter=100000)\n",
    "svc_linear.fit(X_train, y_train)\n",
    "prediction = svc_linear.predict(X_test)\n",
    "svc_linear_score = get_accuracy(prediction)\n",
    "svc_linear_kfold_score = get_kfold_accuracy(svc_linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "centered-advocacy",
   "metadata": {},
   "source": [
    "#### 9.2.17. NuSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-slave",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_nu = svm.NuSVC(probability=True)\n",
    "svc_nu.fit(X_train, y_train)\n",
    "prediction = svc_nu.predict(X_test)\n",
    "svc_nu_score = get_accuracy(prediction)\n",
    "svc_nu_kfold_score = get_kfold_accuracy(svc_nu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "palestinian-costa",
   "metadata": {},
   "source": [
    "#### 9.2.18. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normal-watson",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = tree.DecisionTreeClassifier()\n",
    "decision_tree.fit(X_train, y_train)\n",
    "prediction = decision_tree.predict(X_test)\n",
    "decision_tree_score = get_accuracy(prediction)\n",
    "decision_tree_kfold_score = get_kfold_accuracy(decision_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bored-timber",
   "metadata": {},
   "source": [
    "#### 9.2.19. Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-tonight",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_discriminant = LinearDiscriminantAnalysis()\n",
    "linear_discriminant.fit(X_train, y_train)\n",
    "prediction = linear_discriminant.predict(X_test)\n",
    "linear_discriminant_score = get_accuracy(prediction)\n",
    "linear_discriminant_kfold_score = get_kfold_accuracy(linear_discriminant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improved-benefit",
   "metadata": {},
   "source": [
    "#### 9.2.20. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adapted-acoustic",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgboost = XGBClassifier(random_state=1, objective=\"binary:logistic\", n_estimators=10, eval_metric='mlogloss', use_label_encoder=False)\n",
    "xgboost.fit(X_train, y_train)\n",
    "prediction = xgboost.predict(X_test)\n",
    "xgboost_score = get_accuracy(prediction)\n",
    "xgboost_kfold_score = get_kfold_accuracy(xgboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chemical-classification",
   "metadata": {},
   "source": [
    "#### 9.2.21. Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overall-tobago",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['accuracy', \n",
    "           Precision(),\n",
    "           Recall()]\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=X_train.shape[1], name='Input_'))\n",
    "    model.add(Dense(8, activation='relu', kernel_initializer='glorot_normal', kernel_regularizer=l2(0.001)))\n",
    "    model.add(Dense(16, activation='relu', kernel_initializer='glorot_normal', kernel_regularizer=l2(0.1)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(16, activation='relu', kernel_initializer='glorot_normal', kernel_regularizer=l2(0.1)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_initializer='glorot_normal'))\n",
    "\n",
    "    optimize = Adam(lr = 0.0001)\n",
    "    model.compile(optimizer = optimize,loss = 'binary_crossentropy',metrics = metrics)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valuable-advertising",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "keras = KerasClassifier(build_fn = create_model, epochs = 600, batch_size = 32, verbose = 0)\n",
    "keras.fit(X_train, y_train)\n",
    "prediction = keras.predict(X_test)\n",
    "keras_score = get_accuracy(prediction)\n",
    "# keras_kfold_score = get_kfold_accuracy(keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sporting-dollar",
   "metadata": {},
   "source": [
    "### 9.3. Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shared-cosmetic",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_performance = pd.DataFrame({\n",
    "    \"Model\": [\"Ada Boost\", \n",
    "              \"Bagging\", \n",
    "              \"Keras\", \n",
    "              \"XGBClassifier\", \n",
    "              \"Linear Discriminant Analysis\", \n",
    "              \"Extra Tree\",  \n",
    "              \"Decision Tree\", \n",
    "              \"SVM Nu\",\n",
    "             \"SVM Linear\",\n",
    "             \"SVM\",\n",
    "             \"kNN\",\n",
    "             \"Bernoulli Naive Bayes\",\n",
    "             \"Gaussian Naive Bayes\",\n",
    "             \"SDG\",\n",
    "             \"Passive Aggressive\",\n",
    "             \"Perceptron\",\n",
    "             \"Ridge\",\n",
    "             \"Logistic Regression\",\n",
    "             \"Logistic Regression CV\",\n",
    "             \"Gaussian Process\",\n",
    "             \"Random Forest\",\n",
    "             \"Gradient Boosting\"],\n",
    "    \n",
    "    \"Accuracy\": [ada_boost_score, \n",
    "                 bagging_score, \n",
    "                 keras_score,\n",
    "                xgboost_score,\n",
    "                linear_discriminant_score,\n",
    "                extra_trees_score,\n",
    "                decision_tree_score,\n",
    "                svc_nu_score,\n",
    "                svc_linear_score,\n",
    "                svc_score,\n",
    "                knn_score,\n",
    "                bernoulli_nb_score,\n",
    "                gaussian_nb_score,\n",
    "                sdg_score,\n",
    "                passive_aggressive_score,\n",
    "                perceptron_score,\n",
    "                ridge_score,\n",
    "                logistic_regression_score,\n",
    "                logistic_regression_cv_score,\n",
    "                gaussian_process_score,\n",
    "                random_forest_score,\n",
    "                 gradient_boosting_score,\n",
    "                ]\n",
    "})\n",
    "\n",
    "model_performance.sort_values(by=\"Accuracy\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surgical-dictionary",
   "metadata": {},
   "source": [
    "### 9.4. Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-soviet",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('Gaussian Process',gaussian_process), \n",
    "              ('Linear Discriminant', linear_discriminant),\n",
    "              ('kNN', knn)]\n",
    "\n",
    "stack = StackingClassifier(estimators=estimators)\n",
    "stack.fit(X_train, y_train)\n",
    "prediction = stack.predict(X_test)\n",
    "stack_score = get_accuracy(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inclusive-appeal",
   "metadata": {},
   "source": [
    "### 9.5. Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arctic-making",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting = VotingClassifier(\n",
    "    estimators = [\n",
    "        ('Gaussian Process',gaussian_process),\n",
    "        ('Linear Discriminant Analysis',linear_discriminant),\n",
    "        (\"SVM Nu\", svc_nu),\n",
    "        (\"Knn\", knn),\n",
    "],\n",
    "    voting = 'hard'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinated-angola",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting.fit(X_train, y_train)\n",
    "prediction = voting.predict(X_test)\n",
    "voting_score = get_accuracy(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wired-genetics",
   "metadata": {},
   "source": [
    "### 9.6. Tunning Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "round-screening",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = LogisticRegression(random_state=1)\n",
    "\n",
    "parameters = {\n",
    "    'penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'C' : np.logspace(1, -1),\n",
    "    'solver' : ['liblinear', \"newton-cg\", \"lbfgs\", \"sag\", \"saga\"]\n",
    "}\n",
    "\n",
    "grid_cv = GridSearchCV(rf_clf, parameters, scoring = make_scorer(accuracy_score))\n",
    "grid_cv = grid_cv.fit(X_training, y_training)\n",
    "\n",
    "best_estimator = grid_cv.best_estimator_\n",
    "best_score = grid_cv.best_score_\n",
    "best_params = grid_cv.best_params_\n",
    "\n",
    "best_model = grid_cv.best_estimator_\n",
    "best_model.fit(train_data, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executive-failing",
   "metadata": {},
   "source": [
    "\n",
    "# 10. Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superb-being",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_passenger = passenger_train + passenger_test\n",
    "df_train_final = full_df[full_df[\"PassengerId\"].isin(all_passenger)]\n",
    "X_train = df_train_final.drop([\"PassengerId\", \"Survived\"], axis=1)\n",
    "y_train = df_train_final[\"Survived\"]\n",
    "\n",
    "df_test_final = full_df[~full_df[\"PassengerId\"].isin(all_passenger)]\n",
    "X_test = df_test_final.drop([\"PassengerId\", \"Survived\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appointed-jaguar",
   "metadata": {},
   "source": [
    "### 10.1. Submiting Using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selective-allowance",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras = KerasClassifier(build_fn = create_model, epochs = 600, batch_size = 32, verbose = 0)\n",
    "keras.fit(X_train, y_train)\n",
    "prediction = keras.predict(X_test)\n",
    "y_pred = []\n",
    "for y in prediction:\n",
    "    y_pred.append(y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-combine",
   "metadata": {},
   "source": [
    "### 10.2. Submitting Using Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "japanese-interstate",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_process = GaussianProcessClassifier()\n",
    "gaussian_process.fit(X_train, y_train)\n",
    "\n",
    "linear_discriminant = LinearDiscriminantAnalysis()\n",
    "linear_discriminant.fit(X_train, y_train)\n",
    "\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors = 13)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "estimators = [('Gaussian Process',gaussian_process), \n",
    "              ('Linear Discriminant', linear_discriminant),\n",
    "              ('kNN', knn)]\n",
    "\n",
    "stack = StackingClassifier(estimators=estimators)\n",
    "stack.fit(X_train, y_train)\n",
    "y_pred = stack.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "literary-covering",
   "metadata": {},
   "source": [
    "### 10.3. Submitting Using Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-prescription",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting = VotingClassifier(\n",
    "    estimators = [\n",
    "        ('Gaussian Process',gaussian_process),\n",
    "                  ('Linear Discriminant Analysis',linear_discriminant),\n",
    "                  (\"SVM Nu\", svc_nu),\n",
    "        (\"Knn\", knn),\n",
    "                 ],\n",
    "    voting = 'hard'\n",
    ")\n",
    "\n",
    "voting.fit(X_train, y_train)\n",
    "prediction = voting.predict(X_test)\n",
    "y_pred = stack.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specific-annotation",
   "metadata": {},
   "source": [
    "### 10.4. Final Submission Adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intermediate-condition",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({ \n",
    "    \"PassengerId\": df_test_final[\"PassengerId\"],\n",
    "    \"Survived\": y_pred\n",
    "})\n",
    "submission.Survived = submission.Survived.astype(int)\n",
    "submission.to_csv(r\"../data/submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nonprofit-pulse",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hydraulic-ecuador",
   "metadata": {},
   "source": [
    "# 11. Credits\n",
    "https://www.kaggle.com/sreevishnudamodaran/ultimate-eda-fe-neural-network-model-top-2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
